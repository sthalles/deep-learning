{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with TFLearn\n",
    "\n",
    "In this notebook, we'll continue Andrew Trask's work by building a network for sentiment analysis on the movie review data. Instead of a network written with Numpy, we'll be using [TFLearn](http://tflearn.org/), a high-level library built on top of TensorFlow. TFLearn makes it simpler to build networks just by defining the layers. It takes care of most of the details for you.\n",
    "\n",
    "We'll start off by importing all the modules we'll need, then load and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Following along with Andrew, our goal here is to convert our reviews into word vectors. The word vectors will have elements representing words in the total vocabulary. If the second position represents the word 'the', for each review we'll count up the number of times 'the' appears in the text and set the second position to that count. I'll show you examples as we build the input data from the reviews data. Check out Andrew's notebook and video for more about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Use the pandas library to read the reviews and postive/negative labels from comma-separated files. The data we're using has already been preprocessed a bit and we know it uses only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting word frequency\n",
    "\n",
    "To start off we'll need to count how often each word appears in the data. We'll use this count to create a vocabulary we'll use to encode the review data. This resulting count is known as a [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model). We'll use it to select our vocabulary and build the word vectors. You should have seen how to do this in Andrew's lesson. Try to implement it here using the [Counter class](https://docs.python.org/2/library/collections.html#collections.Counter).\n",
    "\n",
    "> **Exercise:** Create the bag of words from the reviews data and assign it to `total_counts`. The reviews are stores in the `reviews` [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). If you want the reviews as a Numpy array, use `reviews.values`. You can iterate through the rows in the DataFrame with `for idx, row in reviews.iterrows():` ([documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html)). When you break up the reviews into words, use `.split(' ')` instead of `.split()` so your results match ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  74074\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_counts = Counter()\n",
    "\n",
    "for review in reviews.values:\n",
    "    for word in review[0].split(\" \"):\n",
    "        total_counts[word] += 1\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1111930),\n",
       " ('the', 336713),\n",
       " ('.', 327192),\n",
       " ('and', 164107),\n",
       " ('a', 163009),\n",
       " ('of', 145864),\n",
       " ('to', 135720),\n",
       " ('is', 107328),\n",
       " ('br', 101872),\n",
       " ('it', 96352),\n",
       " ('in', 93968),\n",
       " ('i', 87623),\n",
       " ('this', 76000),\n",
       " ('that', 73245),\n",
       " ('s', 65361),\n",
       " ('was', 48208),\n",
       " ('as', 46933),\n",
       " ('for', 44343),\n",
       " ('with', 44125),\n",
       " ('movie', 44039),\n",
       " ('but', 42603),\n",
       " ('film', 40155),\n",
       " ('you', 34230),\n",
       " ('on', 34200),\n",
       " ('t', 34081),\n",
       " ('not', 30626),\n",
       " ('he', 30138),\n",
       " ('are', 29430),\n",
       " ('his', 29374),\n",
       " ('have', 27731),\n",
       " ('be', 26957),\n",
       " ('one', 26789),\n",
       " ('all', 23978),\n",
       " ('at', 23513),\n",
       " ('they', 22906),\n",
       " ('by', 22546),\n",
       " ('an', 21560),\n",
       " ('who', 21433),\n",
       " ('so', 20617),\n",
       " ('from', 20498),\n",
       " ('like', 20276),\n",
       " ('there', 18832),\n",
       " ('her', 18421),\n",
       " ('or', 18004),\n",
       " ('just', 17771),\n",
       " ('about', 17374),\n",
       " ('out', 17113),\n",
       " ('if', 16803),\n",
       " ('has', 16790),\n",
       " ('what', 16159),\n",
       " ('some', 15747),\n",
       " ('good', 15143),\n",
       " ('can', 14654),\n",
       " ('more', 14251),\n",
       " ('she', 14223),\n",
       " ('when', 14182),\n",
       " ('very', 14069),\n",
       " ('up', 13291),\n",
       " ('time', 12724),\n",
       " ('no', 12717),\n",
       " ('even', 12651),\n",
       " ('my', 12503),\n",
       " ('would', 12436),\n",
       " ('which', 12047),\n",
       " ('story', 11988),\n",
       " ('only', 11918),\n",
       " ('really', 11738),\n",
       " ('see', 11478),\n",
       " ('their', 11385),\n",
       " ('had', 11290),\n",
       " ('we', 10859),\n",
       " ('were', 10783),\n",
       " ('me', 10773),\n",
       " ('well', 10659),\n",
       " ('than', 9919),\n",
       " ('much', 9763),\n",
       " ('get', 9309),\n",
       " ('bad', 9308),\n",
       " ('been', 9289),\n",
       " ('people', 9285),\n",
       " ('will', 9211),\n",
       " ('do', 9177),\n",
       " ('other', 9163),\n",
       " ('also', 9158),\n",
       " ('into', 9111),\n",
       " ('first', 9061),\n",
       " ('great', 9059),\n",
       " ('because', 9045),\n",
       " ('how', 8901),\n",
       " ('him', 8876),\n",
       " ('don', 8804),\n",
       " ('most', 8783),\n",
       " ('made', 8364),\n",
       " ('its', 8277),\n",
       " ('then', 8119),\n",
       " ('make', 8025),\n",
       " ('way', 8025),\n",
       " ('them', 7970),\n",
       " ('could', 7923),\n",
       " ('too', 7833),\n",
       " ('movies', 7666),\n",
       " ('any', 7660),\n",
       " ('after', 7638),\n",
       " ('think', 7298),\n",
       " ('characters', 7160),\n",
       " ('character', 7020),\n",
       " ('watch', 6974),\n",
       " ('two', 6906),\n",
       " ('films', 6890),\n",
       " ('seen', 6679),\n",
       " ('many', 6675),\n",
       " ('life', 6628),\n",
       " ('being', 6610),\n",
       " ('plot', 6586),\n",
       " ('acting', 6493),\n",
       " ('never', 6485),\n",
       " ('love', 6453),\n",
       " ('little', 6437),\n",
       " ('best', 6413),\n",
       " ('where', 6392),\n",
       " ('over', 6333),\n",
       " ('did', 6296),\n",
       " ('show', 6294),\n",
       " ('know', 6167),\n",
       " ('off', 6030),\n",
       " ('ever', 5997),\n",
       " ('man', 5976),\n",
       " ('does', 5940),\n",
       " ('here', 5767),\n",
       " ('better', 5739),\n",
       " ('your', 5686),\n",
       " ('end', 5650),\n",
       " ('still', 5623),\n",
       " ('these', 5418),\n",
       " ('say', 5396),\n",
       " ('scene', 5383),\n",
       " ('why', 5318),\n",
       " ('while', 5317),\n",
       " ('scenes', 5212),\n",
       " ('go', 5157),\n",
       " ('ve', 5136),\n",
       " ('such', 5134),\n",
       " ('something', 5077),\n",
       " ('should', 5041),\n",
       " ('m', 4998),\n",
       " ('back', 4971),\n",
       " ('through', 4969),\n",
       " ('real', 4738),\n",
       " ('those', 4697),\n",
       " ('watching', 4606),\n",
       " ('now', 4605),\n",
       " ('though', 4566),\n",
       " ('doesn', 4536),\n",
       " ('thing', 4528),\n",
       " ('old', 4526),\n",
       " ('years', 4517),\n",
       " ('re', 4504),\n",
       " ('actors', 4484),\n",
       " ('director', 4445),\n",
       " ('work', 4373),\n",
       " ('another', 4329),\n",
       " ('before', 4324),\n",
       " ('didn', 4318),\n",
       " ('new', 4312),\n",
       " ('nothing', 4290),\n",
       " ('funny', 4289),\n",
       " ('actually', 4239),\n",
       " ('makes', 4204),\n",
       " ('look', 4147),\n",
       " ('find', 4132),\n",
       " ('going', 4102),\n",
       " ('few', 4076),\n",
       " ('same', 4053),\n",
       " ('part', 4040),\n",
       " ('again', 4007),\n",
       " ('every', 3979),\n",
       " ('lot', 3979),\n",
       " ('world', 3833),\n",
       " ('cast', 3827),\n",
       " ('us', 3790),\n",
       " ('quite', 3739),\n",
       " ('down', 3728),\n",
       " ('want', 3703),\n",
       " ('things', 3688),\n",
       " ('pretty', 3664),\n",
       " ('young', 3660),\n",
       " ('seems', 3619),\n",
       " ('around', 3617),\n",
       " ('horror', 3591),\n",
       " ('got', 3587),\n",
       " ('however', 3535),\n",
       " ('fact', 3523),\n",
       " ('take', 3509),\n",
       " ('big', 3477),\n",
       " ('enough', 3452),\n",
       " ('long', 3451),\n",
       " ('thought', 3437),\n",
       " ('series', 3416),\n",
       " ('both', 3406),\n",
       " ('between', 3390),\n",
       " ('may', 3387),\n",
       " ('original', 3376),\n",
       " ('give', 3376),\n",
       " ('action', 3355),\n",
       " ('own', 3349),\n",
       " ('right', 3313),\n",
       " ('without', 3266),\n",
       " ('must', 3250),\n",
       " ('comedy', 3246),\n",
       " ('always', 3239),\n",
       " ('times', 3238),\n",
       " ('point', 3224),\n",
       " ('gets', 3204),\n",
       " ('family', 3202),\n",
       " ('come', 3189),\n",
       " ('role', 3189),\n",
       " ('isn', 3177),\n",
       " ('saw', 3167),\n",
       " ('almost', 3140),\n",
       " ('interesting', 3129),\n",
       " ('least', 3113),\n",
       " ('done', 3096),\n",
       " ('whole', 3078),\n",
       " ('d', 3077),\n",
       " ('bit', 3055),\n",
       " ('music', 3054),\n",
       " ('guy', 3035),\n",
       " ('script', 3028),\n",
       " ('far', 2977),\n",
       " ('making', 2960),\n",
       " ('minutes', 2953),\n",
       " ('feel', 2951),\n",
       " ('anything', 2949),\n",
       " ('last', 2933),\n",
       " ('might', 2918),\n",
       " ('since', 2907),\n",
       " ('performance', 2896),\n",
       " ('ll', 2893),\n",
       " ('girl', 2853),\n",
       " ('probably', 2842),\n",
       " ('am', 2807),\n",
       " ('woman', 2795),\n",
       " ('kind', 2783),\n",
       " ('tv', 2782),\n",
       " ('away', 2775),\n",
       " ('yet', 2752),\n",
       " ('day', 2746),\n",
       " ('rather', 2734),\n",
       " ('worst', 2732),\n",
       " ('fun', 2693),\n",
       " ('sure', 2686),\n",
       " ('hard', 2668),\n",
       " ('anyone', 2632),\n",
       " ('played', 2588),\n",
       " ('each', 2580),\n",
       " ('found', 2573),\n",
       " ('having', 2546),\n",
       " ('although', 2537),\n",
       " ('especially', 2535),\n",
       " ('our', 2510),\n",
       " ('course', 2506),\n",
       " ('believe', 2505),\n",
       " ('screen', 2493),\n",
       " ('comes', 2484),\n",
       " ('looking', 2483),\n",
       " ('trying', 2473),\n",
       " ('set', 2454),\n",
       " ('goes', 2442),\n",
       " ('book', 2420),\n",
       " ('looks', 2413),\n",
       " ('place', 2411),\n",
       " ('actor', 2388),\n",
       " ('different', 2382),\n",
       " ('put', 2381),\n",
       " ('year', 2361),\n",
       " ('money', 2361),\n",
       " ('ending', 2357),\n",
       " ('dvd', 2345),\n",
       " ('maybe', 2341),\n",
       " ('let', 2339),\n",
       " ('someone', 2337),\n",
       " ('true', 2333),\n",
       " ('once', 2329),\n",
       " ('sense', 2326),\n",
       " ('everything', 2325),\n",
       " ('reason', 2323),\n",
       " ('wasn', 2308),\n",
       " ('shows', 2307),\n",
       " ('three', 2295),\n",
       " ('worth', 2278),\n",
       " ('job', 2277),\n",
       " ('main', 2264),\n",
       " ('together', 2243),\n",
       " ('play', 2238),\n",
       " ('watched', 2236),\n",
       " ('american', 2228),\n",
       " ('everyone', 2223),\n",
       " ('plays', 2213),\n",
       " ('john', 2208),\n",
       " ('effects', 2204),\n",
       " ('later', 2199),\n",
       " ('audience', 2198),\n",
       " ('said', 2196),\n",
       " ('takes', 2192),\n",
       " ('instead', 2190),\n",
       " ('house', 2185),\n",
       " ('beautiful', 2176),\n",
       " ('seem', 2175),\n",
       " ('night', 2165),\n",
       " ('high', 2161),\n",
       " ('himself', 2159),\n",
       " ('version', 2157),\n",
       " ('wife', 2140),\n",
       " ('during', 2130),\n",
       " ('left', 2125),\n",
       " ('father', 2121),\n",
       " ('special', 2113),\n",
       " ('seeing', 2099),\n",
       " ('half', 2094),\n",
       " ('star', 2083),\n",
       " ('excellent', 2071),\n",
       " ('war', 2051),\n",
       " ('shot', 2051),\n",
       " ('idea', 2043),\n",
       " ('black', 2034),\n",
       " ('nice', 2012),\n",
       " ('less', 2001),\n",
       " ('else', 2000),\n",
       " ('mind', 1995),\n",
       " ('simply', 1965),\n",
       " ('read', 1964),\n",
       " ('second', 1962),\n",
       " ('fan', 1911),\n",
       " ('men', 1909),\n",
       " ('death', 1907),\n",
       " ('hollywood', 1906),\n",
       " ('poor', 1897),\n",
       " ('help', 1896),\n",
       " ('completely', 1889),\n",
       " ('used', 1879),\n",
       " ('home', 1877),\n",
       " ('dead', 1877),\n",
       " ('line', 1868),\n",
       " ('either', 1866),\n",
       " ('short', 1866),\n",
       " ('top', 1848),\n",
       " ('given', 1848),\n",
       " ('kids', 1843),\n",
       " ('budget', 1836),\n",
       " ('try', 1831),\n",
       " ('classic', 1829),\n",
       " ('wrong', 1823),\n",
       " ('performances', 1821),\n",
       " ('women', 1816),\n",
       " ('enjoy', 1812),\n",
       " ('boring', 1811),\n",
       " ('need', 1807),\n",
       " ('use', 1804),\n",
       " ('rest', 1803),\n",
       " ('low', 1799),\n",
       " ('friends', 1791),\n",
       " ('production', 1790),\n",
       " ('full', 1779),\n",
       " ('camera', 1777),\n",
       " ('until', 1776),\n",
       " ('along', 1775),\n",
       " ('truly', 1743),\n",
       " ('video', 1731),\n",
       " ('awful', 1725),\n",
       " ('tell', 1718),\n",
       " ('couple', 1718),\n",
       " ('next', 1717),\n",
       " ('remember', 1702),\n",
       " ('stupid', 1701),\n",
       " ('start', 1700),\n",
       " ('stars', 1697),\n",
       " ('perhaps', 1684),\n",
       " ('sex', 1684),\n",
       " ('mean', 1683),\n",
       " ('won', 1679),\n",
       " ('came', 1673),\n",
       " ('recommend', 1668),\n",
       " ('moments', 1665),\n",
       " ('school', 1659),\n",
       " ('wonderful', 1658),\n",
       " ('episode', 1658),\n",
       " ('small', 1646),\n",
       " ('face', 1645),\n",
       " ('understand', 1644),\n",
       " ('terrible', 1638),\n",
       " ('playing', 1633),\n",
       " ('getting', 1627),\n",
       " ('written', 1616),\n",
       " ('early', 1605),\n",
       " ('name', 1604),\n",
       " ('doing', 1603),\n",
       " ('style', 1601),\n",
       " ('keep', 1601),\n",
       " ('often', 1601),\n",
       " ('perfect', 1598),\n",
       " ('human', 1596),\n",
       " ('others', 1595),\n",
       " ('person', 1595),\n",
       " ('definitely', 1580),\n",
       " ('gives', 1577),\n",
       " ('itself', 1562),\n",
       " ('boy', 1560),\n",
       " ('lines', 1553),\n",
       " ('lost', 1552),\n",
       " ('live', 1552),\n",
       " ('become', 1543),\n",
       " ('dialogue', 1542),\n",
       " ('head', 1541),\n",
       " ('piece', 1537),\n",
       " ('finally', 1536),\n",
       " ('case', 1533),\n",
       " ('yes', 1532),\n",
       " ('felt', 1528),\n",
       " ('mother', 1523),\n",
       " ('supposed', 1516),\n",
       " ('liked', 1516),\n",
       " ('children', 1509),\n",
       " ('title', 1497),\n",
       " ('cinema', 1493),\n",
       " ('couldn', 1493),\n",
       " ('white', 1491),\n",
       " ('absolutely', 1485),\n",
       " ('picture', 1484),\n",
       " ('against', 1477),\n",
       " ('sort', 1472),\n",
       " ('worse', 1469),\n",
       " ('certainly', 1463),\n",
       " ('went', 1463),\n",
       " ('entire', 1461),\n",
       " ('waste', 1457),\n",
       " ('killer', 1455),\n",
       " ('problem', 1450),\n",
       " ('oh', 1449),\n",
       " ('mr', 1448),\n",
       " ('hope', 1447),\n",
       " ('evil', 1446),\n",
       " ('entertaining', 1443),\n",
       " ('friend', 1442),\n",
       " ('overall', 1437),\n",
       " ('called', 1433),\n",
       " ('based', 1431),\n",
       " ('loved', 1428),\n",
       " ('fans', 1421),\n",
       " ('several', 1420),\n",
       " ('drama', 1411),\n",
       " ('beginning', 1401),\n",
       " ('lives', 1393),\n",
       " ('direction', 1385),\n",
       " ('care', 1385),\n",
       " ('dark', 1381),\n",
       " ('already', 1381),\n",
       " ('becomes', 1380),\n",
       " ('laugh', 1375),\n",
       " ('example', 1371),\n",
       " ('under', 1368),\n",
       " ('despite', 1364),\n",
       " ('seemed', 1363),\n",
       " ('throughout', 1361),\n",
       " ('turn', 1359),\n",
       " ('son', 1356),\n",
       " ('unfortunately', 1353),\n",
       " ('wanted', 1352),\n",
       " ('michael', 1333),\n",
       " ('history', 1331),\n",
       " ('heart', 1328),\n",
       " ('final', 1327),\n",
       " ('child', 1324),\n",
       " ('fine', 1324),\n",
       " ('amazing', 1320),\n",
       " ('sound', 1320),\n",
       " ('guess', 1311),\n",
       " ('lead', 1310),\n",
       " ('humor', 1309),\n",
       " ('totally', 1307),\n",
       " ('writing', 1304),\n",
       " ('guys', 1303),\n",
       " ('quality', 1301),\n",
       " ('close', 1296),\n",
       " ('art', 1289),\n",
       " ('wants', 1288),\n",
       " ('game', 1283),\n",
       " ('works', 1279),\n",
       " ('behind', 1279),\n",
       " ('town', 1278),\n",
       " ('side', 1276),\n",
       " ('tries', 1274),\n",
       " ('days', 1268),\n",
       " ('past', 1263),\n",
       " ('viewer', 1262),\n",
       " ('able', 1259),\n",
       " ('flick', 1258),\n",
       " ('hand', 1257),\n",
       " ('genre', 1255),\n",
       " ('act', 1251),\n",
       " ('turns', 1251),\n",
       " ('enjoyed', 1246),\n",
       " ('today', 1245),\n",
       " ('kill', 1234),\n",
       " ('favorite', 1232),\n",
       " ('car', 1224),\n",
       " ('soon', 1223),\n",
       " ('starts', 1220),\n",
       " ('run', 1219),\n",
       " ('actress', 1219),\n",
       " ('sometimes', 1218),\n",
       " ('eyes', 1217),\n",
       " ('gave', 1217),\n",
       " ('b', 1212),\n",
       " ('girls', 1211),\n",
       " ('late', 1211),\n",
       " ('etc', 1210),\n",
       " ('god', 1208),\n",
       " ('directed', 1204),\n",
       " ('horrible', 1201),\n",
       " ('kid', 1200),\n",
       " ('city', 1197),\n",
       " ('brilliant', 1196),\n",
       " ('parts', 1191),\n",
       " ('hour', 1187),\n",
       " ('blood', 1186),\n",
       " ('self', 1185),\n",
       " ('themselves', 1184),\n",
       " ('stories', 1180),\n",
       " ('thinking', 1179),\n",
       " ('expect', 1178),\n",
       " ('stuff', 1174),\n",
       " ('obviously', 1163),\n",
       " ('decent', 1157),\n",
       " ('voice', 1156),\n",
       " ('writer', 1152),\n",
       " ('highly', 1148),\n",
       " ('fight', 1148),\n",
       " ('myself', 1147),\n",
       " ('feeling', 1145),\n",
       " ('daughter', 1138),\n",
       " ('slow', 1132),\n",
       " ('except', 1130),\n",
       " ('matter', 1127),\n",
       " ('type', 1125),\n",
       " ('age', 1119),\n",
       " ('anyway', 1117),\n",
       " ('roles', 1113),\n",
       " ('moment', 1112),\n",
       " ('killed', 1111),\n",
       " ('heard', 1111),\n",
       " ('says', 1110),\n",
       " ('leave', 1106),\n",
       " ('brother', 1105),\n",
       " ('took', 1100),\n",
       " ('strong', 1098),\n",
       " ('police', 1097),\n",
       " ('cannot', 1097),\n",
       " ('violence', 1092),\n",
       " ('hit', 1087),\n",
       " ('stop', 1084),\n",
       " ('happens', 1081),\n",
       " ('known', 1079),\n",
       " ('particularly', 1078),\n",
       " ('involved', 1077),\n",
       " ('happened', 1076),\n",
       " ('chance', 1069),\n",
       " ('extremely', 1069),\n",
       " ('james', 1068),\n",
       " ('obvious', 1066),\n",
       " ('murder', 1063),\n",
       " ('living', 1063),\n",
       " ('told', 1063),\n",
       " ('coming', 1062),\n",
       " ('alone', 1061),\n",
       " ('experience', 1059),\n",
       " ('lack', 1058),\n",
       " ('hero', 1055),\n",
       " ('wouldn', 1054),\n",
       " ('including', 1052),\n",
       " ('attempt', 1050),\n",
       " ('please', 1047),\n",
       " ('happen', 1044),\n",
       " ('gore', 1043),\n",
       " ('crap', 1039),\n",
       " ('wonder', 1038),\n",
       " ('cut', 1035),\n",
       " ('group', 1034),\n",
       " ('complete', 1034),\n",
       " ('interest', 1033),\n",
       " ('ago', 1033),\n",
       " ('score', 1030),\n",
       " ('none', 1030),\n",
       " ('husband', 1026),\n",
       " ('save', 1023),\n",
       " ('hell', 1023),\n",
       " ('david', 1023),\n",
       " ('simple', 1022),\n",
       " ('ok', 1018),\n",
       " ('looked', 1010),\n",
       " ('song', 1008),\n",
       " ('career', 1007),\n",
       " ('number', 1006),\n",
       " ('seriously', 1001),\n",
       " ('possible', 1000),\n",
       " ('annoying', 998),\n",
       " ('sad', 996),\n",
       " ('exactly', 995),\n",
       " ('shown', 994),\n",
       " ('king', 993),\n",
       " ('musical', 992),\n",
       " ('running', 992),\n",
       " ('yourself', 989),\n",
       " ('serious', 989),\n",
       " ('scary', 988),\n",
       " ('reality', 987),\n",
       " ('taken', 987),\n",
       " ('whose', 986),\n",
       " ('released', 986),\n",
       " ('cinematography', 985),\n",
       " ('english', 985),\n",
       " ('ends', 984),\n",
       " ('hours', 983),\n",
       " ('usually', 981),\n",
       " ('opening', 979),\n",
       " ('light', 976),\n",
       " ('jokes', 976),\n",
       " ('hilarious', 972),\n",
       " ('cool', 971),\n",
       " ('across', 971),\n",
       " ('body', 970),\n",
       " ('somewhat', 966),\n",
       " ('relationship', 965),\n",
       " ('ridiculous', 965),\n",
       " ('happy', 965),\n",
       " ('usual', 965),\n",
       " ('view', 964),\n",
       " ('started', 963),\n",
       " ('level', 963),\n",
       " ('change', 961),\n",
       " ('opinion', 959),\n",
       " ('novel', 957),\n",
       " ('wish', 957),\n",
       " ('middle', 956),\n",
       " ('taking', 955),\n",
       " ('talking', 955),\n",
       " ('documentary', 953),\n",
       " ('ones', 952),\n",
       " ('robert', 951),\n",
       " ('order', 949),\n",
       " ('finds', 948),\n",
       " ('shots', 948),\n",
       " ('power', 947),\n",
       " ('female', 946),\n",
       " ('saying', 946),\n",
       " ('huge', 945),\n",
       " ('room', 944),\n",
       " ('mostly', 940),\n",
       " ('episodes', 939),\n",
       " ('country', 934),\n",
       " ('talent', 933),\n",
       " ('five', 933),\n",
       " ('important', 931),\n",
       " ('rating', 930),\n",
       " ('modern', 929),\n",
       " ('earth', 928),\n",
       " ('major', 927),\n",
       " ('word', 927),\n",
       " ('strange', 927),\n",
       " ('turned', 925),\n",
       " ('call', 923),\n",
       " ('jack', 922),\n",
       " ('single', 918),\n",
       " ('apparently', 918),\n",
       " ('disappointed', 917),\n",
       " ('four', 911),\n",
       " ('events', 911),\n",
       " ('due', 909),\n",
       " ('songs', 908),\n",
       " ('basically', 906),\n",
       " ('attention', 905),\n",
       " ('television', 903),\n",
       " ('comic', 901),\n",
       " ('knows', 901),\n",
       " ('future', 899),\n",
       " ('supporting', 899),\n",
       " ('clearly', 899),\n",
       " ('non', 899),\n",
       " ('knew', 898),\n",
       " ('british', 898),\n",
       " ('paul', 897),\n",
       " ('fast', 897),\n",
       " ('thriller', 897),\n",
       " ('class', 893),\n",
       " ('easily', 892),\n",
       " ('cheap', 892),\n",
       " ('silly', 889),\n",
       " ('problems', 887),\n",
       " ('aren', 886),\n",
       " ('words', 884),\n",
       " ('miss', 882),\n",
       " ('tells', 881),\n",
       " ('entertainment', 879),\n",
       " ('local', 877),\n",
       " ('sequence', 875),\n",
       " ('rock', 875),\n",
       " ('bring', 869),\n",
       " ('beyond', 866),\n",
       " ('george', 864),\n",
       " ('straight', 864),\n",
       " ('oscar', 861),\n",
       " ('o', 859),\n",
       " ('upon', 859),\n",
       " ('whether', 856),\n",
       " ('romantic', 856),\n",
       " ('predictable', 854),\n",
       " ('moving', 854),\n",
       " ('similar', 852),\n",
       " ('sets', 852),\n",
       " ('review', 851),\n",
       " ('eye', 851),\n",
       " ('falls', 851),\n",
       " ('mystery', 850),\n",
       " ('lady', 848),\n",
       " ('richard', 846),\n",
       " ('talk', 842),\n",
       " ('enjoyable', 842),\n",
       " ('needs', 841),\n",
       " ('appears', 841),\n",
       " ('giving', 839),\n",
       " ('within', 832),\n",
       " ('message', 829),\n",
       " ('theater', 828),\n",
       " ('ten', 828),\n",
       " ('animation', 826),\n",
       " ('team', 824),\n",
       " ('near', 824),\n",
       " ('above', 819),\n",
       " ('red', 818),\n",
       " ('sister', 818),\n",
       " ('sequel', 818),\n",
       " ('theme', 816),\n",
       " ('dull', 816),\n",
       " ('nearly', 815),\n",
       " ('stand', 815),\n",
       " ('lee', 814),\n",
       " ('bunch', 813),\n",
       " ('points', 812),\n",
       " ('mention', 811),\n",
       " ('add', 810),\n",
       " ('york', 810),\n",
       " ('herself', 810),\n",
       " ('feels', 810),\n",
       " ('haven', 809),\n",
       " ('release', 807),\n",
       " ('storyline', 804),\n",
       " ('ways', 804),\n",
       " ('easy', 802),\n",
       " ('surprised', 802),\n",
       " ('using', 801),\n",
       " ('named', 800),\n",
       " ('fantastic', 797),\n",
       " ('begins', 796),\n",
       " ('lots', 796),\n",
       " ('die', 794),\n",
       " ('working', 794),\n",
       " ('actual', 793),\n",
       " ('effort', 792),\n",
       " ('feature', 791),\n",
       " ('tale', 789),\n",
       " ('french', 789),\n",
       " ('minute', 789),\n",
       " ('hate', 788),\n",
       " ('stay', 787),\n",
       " ('follow', 787),\n",
       " ('viewers', 786),\n",
       " ('clear', 786),\n",
       " ('tom', 784),\n",
       " ('elements', 783),\n",
       " ('among', 782),\n",
       " ('comments', 779),\n",
       " ('typical', 778),\n",
       " ('showing', 775),\n",
       " ('avoid', 775),\n",
       " ('editing', 775),\n",
       " ('season', 773),\n",
       " ('tried', 773),\n",
       " ('famous', 772),\n",
       " ('sorry', 771),\n",
       " ('fall', 770),\n",
       " ('dialog', 769),\n",
       " ('check', 769),\n",
       " ('peter', 768),\n",
       " ('period', 767),\n",
       " ('certain', 765),\n",
       " ('form', 765),\n",
       " ('buy', 764),\n",
       " ('general', 764),\n",
       " ('filmed', 764),\n",
       " ('soundtrack', 764),\n",
       " ('parents', 763),\n",
       " ('weak', 762),\n",
       " ('means', 761),\n",
       " ('material', 761),\n",
       " ('realistic', 758),\n",
       " ('figure', 758),\n",
       " ('doubt', 757),\n",
       " ('crime', 757),\n",
       " ('somehow', 757),\n",
       " ('space', 755),\n",
       " ('disney', 754),\n",
       " ('gone', 754),\n",
       " ('kept', 750),\n",
       " ('viewing', 750),\n",
       " ('leads', 749),\n",
       " ('greatest', 745),\n",
       " ('th', 745),\n",
       " ('dance', 744),\n",
       " ('lame', 742),\n",
       " ('suspense', 741),\n",
       " ('zombie', 740),\n",
       " ('third', 738),\n",
       " ('brought', 737),\n",
       " ('imagine', 736),\n",
       " ('atmosphere', 735),\n",
       " ('hear', 734),\n",
       " ('whatever', 732),\n",
       " ('particular', 730),\n",
       " ('de', 729),\n",
       " ('america', 728),\n",
       " ('sequences', 727),\n",
       " ('move', 726),\n",
       " ('indeed', 722),\n",
       " ('rent', 721),\n",
       " ('eventually', 720),\n",
       " ('average', 720),\n",
       " ('learn', 720),\n",
       " ('wait', 719),\n",
       " ('reviews', 718),\n",
       " ('forget', 718),\n",
       " ('note', 717),\n",
       " ('deal', 717),\n",
       " ('japanese', 716),\n",
       " ('surprise', 715),\n",
       " ('poorly', 714),\n",
       " ('sexual', 714),\n",
       " ('stage', 714),\n",
       " ('okay', 713),\n",
       " ('premise', 712),\n",
       " ('believable', 711),\n",
       " ('sit', 710),\n",
       " ('possibly', 709),\n",
       " ('subject', 709),\n",
       " ('nature', 709),\n",
       " ('decided', 705),\n",
       " ('expected', 704),\n",
       " ('dr', 700),\n",
       " ('imdb', 700),\n",
       " ('truth', 700),\n",
       " ('street', 699),\n",
       " ('became', 697),\n",
       " ('free', 697),\n",
       " ('difficult', 695),\n",
       " ('screenplay', 695),\n",
       " ('romance', 694),\n",
       " ('killing', 694),\n",
       " ('baby', 692),\n",
       " ('joe', 691),\n",
       " ('dog', 688),\n",
       " ('nor', 686),\n",
       " ('hot', 686),\n",
       " ('reading', 685),\n",
       " ('question', 685),\n",
       " ('needed', 683),\n",
       " ('leaves', 683),\n",
       " ('begin', 678),\n",
       " ('meets', 677),\n",
       " ('directors', 676),\n",
       " ('society', 676),\n",
       " ('unless', 675),\n",
       " ('credits', 673),\n",
       " ('otherwise', 671),\n",
       " ('shame', 671),\n",
       " ('superb', 671),\n",
       " ('write', 670),\n",
       " ('situation', 669),\n",
       " ('meet', 668),\n",
       " ('dramatic', 667),\n",
       " ('memorable', 666),\n",
       " ('male', 666),\n",
       " ('open', 665),\n",
       " ('writers', 663),\n",
       " ('earlier', 663),\n",
       " ('badly', 663),\n",
       " ('dream', 663),\n",
       " ('weird', 663),\n",
       " ('fi', 661),\n",
       " ('forced', 661),\n",
       " ('acted', 660),\n",
       " ('sci', 658),\n",
       " ('crazy', 657),\n",
       " ('jane', 657),\n",
       " ('laughs', 657),\n",
       " ('emotional', 657),\n",
       " ('older', 656),\n",
       " ('beauty', 655),\n",
       " ('monster', 655),\n",
       " ('realize', 654),\n",
       " ('comment', 653),\n",
       " ('deep', 652),\n",
       " ('footage', 651),\n",
       " ('forward', 651),\n",
       " ('interested', 651),\n",
       " ('fantasy', 648),\n",
       " ('ask', 648),\n",
       " ('mark', 645),\n",
       " ('whom', 645),\n",
       " ('sounds', 645),\n",
       " ('plus', 645),\n",
       " ('directing', 644),\n",
       " ('keeps', 642),\n",
       " ('development', 642),\n",
       " ('features', 642),\n",
       " ('mess', 641),\n",
       " ('air', 639),\n",
       " ('quickly', 639),\n",
       " ('creepy', 638),\n",
       " ('box', 638),\n",
       " ('towards', 637),\n",
       " ('perfectly', 637),\n",
       " ('girlfriend', 637),\n",
       " ('worked', 635),\n",
       " ('unique', 634),\n",
       " ('cheesy', 634),\n",
       " ('setting', 634),\n",
       " ('effect', 633),\n",
       " ('plenty', 632),\n",
       " ('bill', 632),\n",
       " ('hands', 632),\n",
       " ('total', 632),\n",
       " ('result', 631),\n",
       " ('brings', 630),\n",
       " ('fire', 630),\n",
       " ('previous', 630),\n",
       " ('personal', 629),\n",
       " ('incredibly', 628),\n",
       " ('rate', 626),\n",
       " ('business', 625),\n",
       " ('doctor', 624),\n",
       " ('joke', 624),\n",
       " ('casting', 623),\n",
       " ('apart', 623),\n",
       " ('return', 623),\n",
       " ('christmas', 623),\n",
       " ('leading', 622),\n",
       " ('e', 622),\n",
       " ('admit', 621),\n",
       " ('appear', 620),\n",
       " ('cop', 620),\n",
       " ('powerful', 620),\n",
       " ('background', 619),\n",
       " ('boys', 618),\n",
       " ('ben', 617),\n",
       " ('present', 616),\n",
       " ('meant', 615),\n",
       " ('era', 614),\n",
       " ('telling', 614),\n",
       " ('battle', 614),\n",
       " ('hardly', 613),\n",
       " ('break', 613),\n",
       " ('create', 612),\n",
       " ('potential', 612),\n",
       " ('masterpiece', 612),\n",
       " ('secret', 611),\n",
       " ('pay', 610),\n",
       " ('political', 609),\n",
       " ('gay', 608),\n",
       " ('fighting', 607),\n",
       " ('dumb', 607),\n",
       " ('fails', 606),\n",
       " ('twist', 606),\n",
       " ('various', 604),\n",
       " ('co', 602),\n",
       " ('portrayed', 601),\n",
       " ('villain', 600),\n",
       " ('inside', 600),\n",
       " ('western', 599),\n",
       " ('outside', 598),\n",
       " ('nudity', 598),\n",
       " ('william', 596),\n",
       " ('reasons', 596),\n",
       " ('front', 595),\n",
       " ('ideas', 595),\n",
       " ('match', 594),\n",
       " ('missing', 594),\n",
       " ('deserves', 591),\n",
       " ('married', 590),\n",
       " ('expecting', 588),\n",
       " ('fairly', 587),\n",
       " ('rich', 587),\n",
       " ('talented', 586),\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the first 10000 most frequent words. As Andrew noted, most of the words in the vocabulary are rarely used so they will have little effect on our predictions. Below, we'll sort `vocab` by the count value and keep the 10000 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'the', '.', 'and', 'a', 'of', 'to', 'is', 'br', 'it', 'in', 'i', 'this', 'that', 's', 'was', 'as', 'for', 'with', 'movie', 'but', 'film', 'you', 'on', 't', 'not', 'he', 'are', 'his', 'have', 'be', 'one', 'all', 'at', 'they', 'by', 'an', 'who', 'so', 'from', 'like', 'there', 'her', 'or', 'just', 'about', 'out', 'if', 'has', 'what', 'some', 'good', 'can', 'more', 'she', 'when', 'very', 'up', 'time', 'no']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:10000]\n",
    "print(vocab[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the last word in our vocabulary? We can use this to judge if 10000 is too few. If the last word is pretty common, we probably need to keep more words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registered :  30\n"
     ]
    }
   ],
   "source": [
    "print(vocab[-1], ': ', total_counts[vocab[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last word in our vocabulary shows up in 30 reviews out of 25000. I think it's fair to say this is a tiny proportion of reviews. We are probably fine with this number of words.\n",
    "\n",
    "**Note:** When you run, you may see a different word from the one shown above, but it will also have the value `30`. That's because there are many words tied for that number of counts, and the `Counter` class does not guarantee which one will be returned in the case of a tie.\n",
    "\n",
    "Now for each review in the data, we'll make a word vector. First we need to make a mapping of word to index, pretty easy to do with a dictionary comprehension.\n",
    "\n",
    "> **Exercise:** Create a dictionary called `word2idx` that maps each word in the vocabulary to an index. The first word in `vocab` has index `0`, the second word has index `1`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx = dict() ## create the word-to-index dictionary here\n",
    "for id, word in enumerate(vocab):\n",
    "    word2idx[word] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'satisfied': 4054,\n",
       " 'dear': 3156,\n",
       " 'bathtub': 9958,\n",
       " 'shoulder': 5326,\n",
       " 'hate': 771,\n",
       " 'love': 116,\n",
       " 'problem': 436,\n",
       " 'mob': 2993,\n",
       " 'tendency': 6546,\n",
       " 'deeply': 1659,\n",
       " 'duties': 9379,\n",
       " 'greek': 3868,\n",
       " 'rolling': 2643,\n",
       " 'calls': 1985,\n",
       " 'finale': 1941,\n",
       " 'clumsily': 9358,\n",
       " 'lions': 8363,\n",
       " 'feat': 5786,\n",
       " 'hines': 7286,\n",
       " 'praise': 2797,\n",
       " 'is': 7,\n",
       " 'christy': 4390,\n",
       " 'subsequently': 7676,\n",
       " 'victory': 5072,\n",
       " 'remembers': 6749,\n",
       " 'views': 2669,\n",
       " 'antonio': 5977,\n",
       " 'amazed': 2644,\n",
       " 'denial': 8506,\n",
       " 'leaving': 1179,\n",
       " 'suggestion': 5876,\n",
       " 'dramas': 3256,\n",
       " 'color': 1375,\n",
       " 'invented': 5067,\n",
       " 'borrows': 8564,\n",
       " 'guilty': 2478,\n",
       " 'wait': 836,\n",
       " 'great': 86,\n",
       " 'seek': 2701,\n",
       " 'investigator': 7144,\n",
       " 'oddly': 2958,\n",
       " 'offer': 1441,\n",
       " 'joke': 948,\n",
       " 'wipe': 9289,\n",
       " 'international': 1948,\n",
       " 'neck': 3243,\n",
       " 'potentially': 4592,\n",
       " 'pierre': 6516,\n",
       " 'guy': 226,\n",
       " 'previously': 2418,\n",
       " 'urban': 2574,\n",
       " 'yellow': 4055,\n",
       " 'hustler': 8717,\n",
       " 'lure': 8814,\n",
       " 'kirk': 3830,\n",
       " 'counted': 9093,\n",
       " 'chewing': 7545,\n",
       " 'pain': 1436,\n",
       " 'combining': 8118,\n",
       " 'swim': 4959,\n",
       " 'reviewer': 2125,\n",
       " 'freaks': 5384,\n",
       " 'perry': 3585,\n",
       " 'splatter': 4273,\n",
       " 'users': 6224,\n",
       " 'shift': 6693,\n",
       " 'eventual': 6304,\n",
       " 'fleshed': 6525,\n",
       " 'max': 2320,\n",
       " 'gackt': 7233,\n",
       " 'appalled': 8800,\n",
       " 'shakespeare': 1778,\n",
       " 'joan': 1745,\n",
       " 'automatic': 7896,\n",
       " 'low': 359,\n",
       " 'stefan': 9631,\n",
       " 'puppet': 5035,\n",
       " 'children': 421,\n",
       " 'occult': 7180,\n",
       " 'conduct': 9156,\n",
       " 'killer': 435,\n",
       " 'illness': 4693,\n",
       " 'dud': 4967,\n",
       " 'remain': 2378,\n",
       " 'pronounced': 9988,\n",
       " 'curiosity': 3561,\n",
       " 'effective': 1110,\n",
       " 'ancient': 2183,\n",
       " 'contacts': 9697,\n",
       " 'penis': 8507,\n",
       " 'bored': 1078,\n",
       " 'black': 324,\n",
       " 'betrayed': 7750,\n",
       " 'lessons': 3059,\n",
       " 'converted': 9265,\n",
       " 'morgan': 1893,\n",
       " 'cheat': 8904,\n",
       " 'branagh': 2622,\n",
       " 'activities': 4970,\n",
       " 'thought': 196,\n",
       " 'replacement': 7187,\n",
       " 'high': 309,\n",
       " 'distract': 6547,\n",
       " 'gripping': 3103,\n",
       " 'mouse': 2838,\n",
       " 'wearing': 1636,\n",
       " 'unusually': 6929,\n",
       " 'lifestyle': 4138,\n",
       " 'plants': 9094,\n",
       " 'positions': 9670,\n",
       " 'gentlemen': 6491,\n",
       " 'impressive': 1134,\n",
       " 'dawson': 3436,\n",
       " 'rounded': 5623,\n",
       " 'clothes': 1628,\n",
       " 'btk': 9321,\n",
       " 'feels': 751,\n",
       " 'esquire': 6427,\n",
       " 'turner': 3628,\n",
       " 'focused': 2428,\n",
       " 'whole': 222,\n",
       " 'capturing': 4718,\n",
       " 'wellington': 9402,\n",
       " 'explosion': 3891,\n",
       " 'handsome': 2225,\n",
       " 'heartbreaking': 5400,\n",
       " 'footage': 909,\n",
       " 'holds': 1758,\n",
       " 'sydney': 6510,\n",
       " 'walken': 3235,\n",
       " 'senator': 7706,\n",
       " 'business': 946,\n",
       " 'crashed': 8022,\n",
       " 'backyard': 9082,\n",
       " 'uneven': 4023,\n",
       " 'c': 1014,\n",
       " 'weak': 800,\n",
       " 'amateurish': 2317,\n",
       " 'nazi': 2556,\n",
       " 'carell': 4731,\n",
       " 'intentional': 6548,\n",
       " 'paying': 2637,\n",
       " 'wolf': 3684,\n",
       " 'expectations': 1371,\n",
       " 'soprano': 7026,\n",
       " 'native': 2139,\n",
       " 'allen': 1368,\n",
       " 'demand': 4649,\n",
       " 'jolie': 6680,\n",
       " 'driver': 2507,\n",
       " 'feared': 8976,\n",
       " 'undead': 5904,\n",
       " 'sucks': 1854,\n",
       " 'placement': 8259,\n",
       " 'shell': 6023,\n",
       " 'misplaced': 9471,\n",
       " 'finely': 8590,\n",
       " 'evans': 7345,\n",
       " 'brennan': 8364,\n",
       " 'childhood': 1524,\n",
       " 'jacques': 6643,\n",
       " 'comedies': 1260,\n",
       " 'commenting': 5899,\n",
       " 'conclude': 5668,\n",
       " 'parties': 4763,\n",
       " 'joyous': 9959,\n",
       " 'uncredited': 8663,\n",
       " 'scriptwriter': 8345,\n",
       " 'bravo': 6070,\n",
       " 'rejects': 7025,\n",
       " 'milland': 9931,\n",
       " 'eastwood': 3297,\n",
       " 'karloff': 3123,\n",
       " 'staged': 3923,\n",
       " 'backdrops': 9083,\n",
       " 'believe': 261,\n",
       " 'toro': 8383,\n",
       " 'started': 636,\n",
       " 'com': 2302,\n",
       " 'gang': 1310,\n",
       " 'skill': 2690,\n",
       " 'pre': 1685,\n",
       " 'hides': 5884,\n",
       " 'dusty': 9428,\n",
       " 'alison': 4769,\n",
       " 'storm': 3051,\n",
       " 'hears': 5184,\n",
       " 'channel': 1254,\n",
       " 'blue': 1288,\n",
       " 'perfection': 3193,\n",
       " 'mentally': 2959,\n",
       " 'claire': 2782,\n",
       " 'y': 4633,\n",
       " 'predict': 5669,\n",
       " 'goer': 9657,\n",
       " 'rat': 4004,\n",
       " 'fluff': 5499,\n",
       " 'protecting': 8838,\n",
       " 'eerie': 3240,\n",
       " 'lock': 5223,\n",
       " 'successfully': 2938,\n",
       " 'moe': 5860,\n",
       " 'roger': 2433,\n",
       " 'shock': 1425,\n",
       " 'side': 489,\n",
       " 'world': 177,\n",
       " 'graves': 9221,\n",
       " 'jason': 1615,\n",
       " 'likable': 1429,\n",
       " 'baby': 865,\n",
       " 'oblivious': 7757,\n",
       " 'trio': 3899,\n",
       " 'anxious': 6912,\n",
       " 'shameful': 7691,\n",
       " 'financial': 4087,\n",
       " 'aniston': 7837,\n",
       " 'rambling': 7096,\n",
       " 'quaint': 7925,\n",
       " 'kitty': 5410,\n",
       " 'colleague': 7554,\n",
       " 'frank': 1223,\n",
       " 'cd': 4355,\n",
       " 'butchered': 8213,\n",
       " 'when': 55,\n",
       " 'audition': 5941,\n",
       " 'fawcett': 8215,\n",
       " 'simultaneously': 5185,\n",
       " 'excited': 2210,\n",
       " 'button': 4415,\n",
       " 'introduction': 2839,\n",
       " 'stab': 8100,\n",
       " 'explore': 3721,\n",
       " 'tool': 6439,\n",
       " 'necessarily': 2689,\n",
       " 'vanishing': 9457,\n",
       " 'ignoring': 7251,\n",
       " 'blessed': 8225,\n",
       " 'narrow': 6057,\n",
       " 'cells': 7806,\n",
       " 'peoples': 4239,\n",
       " 'barbara': 2108,\n",
       " 'specifically': 4246,\n",
       " 'lab': 3411,\n",
       " 'nonsense': 1825,\n",
       " 'critics': 1386,\n",
       " 'picked': 1617,\n",
       " 'ash': 8810,\n",
       " 'loyal': 4264,\n",
       " 'mask': 2274,\n",
       " 'crook': 9453,\n",
       " 'leading': 953,\n",
       " 'official': 4065,\n",
       " 'inside': 984,\n",
       " 'nanny': 9698,\n",
       " 'immigrant': 6828,\n",
       " 'winchester': 5775,\n",
       " 'graham': 4778,\n",
       " 'amid': 8365,\n",
       " 'shameless': 7596,\n",
       " 'extraordinary': 2791,\n",
       " 'presented': 1331,\n",
       " 'spice': 6609,\n",
       " 'redundant': 6652,\n",
       " 'changed': 1169,\n",
       " 'adventures': 2425,\n",
       " 'masturbation': 9530,\n",
       " 'amy': 4141,\n",
       " 'hammer': 3904,\n",
       " 'execution': 2575,\n",
       " 'chuckle': 5438,\n",
       " 'freaky': 6469,\n",
       " 'honesty': 4294,\n",
       " 'stepped': 9359,\n",
       " 'comedian': 2973,\n",
       " 'unpleasant': 3945,\n",
       " 'plans': 2426,\n",
       " 'achieves': 6712,\n",
       " 'remember': 372,\n",
       " 'turns': 499,\n",
       " 'wright': 7044,\n",
       " 'hangs': 5890,\n",
       " 'kills': 1076,\n",
       " 'hilarity': 5755,\n",
       " 'themes': 1302,\n",
       " 'tension': 1055,\n",
       " 'growth': 6090,\n",
       " 'flowers': 5688,\n",
       " 'insists': 5633,\n",
       " 'pops': 4678,\n",
       " 'classics': 2181,\n",
       " 'crude': 2608,\n",
       " 'morgana': 9114,\n",
       " 'professor': 2382,\n",
       " 'thoughts': 2295,\n",
       " 'matching': 9403,\n",
       " 'detective': 1217,\n",
       " 'lukas': 5709,\n",
       " 'thumbs': 3340,\n",
       " 'gestures': 7238,\n",
       " 'virtual': 6674,\n",
       " 'animated': 1101,\n",
       " 'goods': 6497,\n",
       " 'feminist': 4912,\n",
       " 'influences': 8137,\n",
       " 'through': 146,\n",
       " 'defense': 4807,\n",
       " 'simmons': 4913,\n",
       " 'foremost': 7252,\n",
       " 'widow': 4105,\n",
       " 'bonnie': 6813,\n",
       " 'horrifying': 4400,\n",
       " 'dirt': 5268,\n",
       " 'prior': 2534,\n",
       " 'supplies': 9619,\n",
       " 'fiend': 7856,\n",
       " 'assassination': 5811,\n",
       " 'thompson': 4843,\n",
       " 'rooms': 4286,\n",
       " 'taped': 6560,\n",
       " 'slightly': 1057,\n",
       " 'search': 1770,\n",
       " 'because': 87,\n",
       " 'snowman': 7050,\n",
       " 'hats': 6006,\n",
       " 'wondrous': 9637,\n",
       " 'factory': 3229,\n",
       " 'hack': 5507,\n",
       " 'remained': 5153,\n",
       " 'tense': 3070,\n",
       " 'starship': 8179,\n",
       " 'graphic': 2137,\n",
       " 'spectacle': 6404,\n",
       " 'bickering': 9901,\n",
       " 'fuss': 8641,\n",
       " 'authority': 4234,\n",
       " 'townsend': 9671,\n",
       " 'stranded': 6356,\n",
       " 'torment': 8104,\n",
       " 'empty': 1882,\n",
       " 'seats': 7152,\n",
       " 'spears': 9395,\n",
       " 'described': 2182,\n",
       " 'before': 161,\n",
       " 'conclusions': 7764,\n",
       " 'payne': 7915,\n",
       " 'manufactured': 9404,\n",
       " 'menacing': 3515,\n",
       " 'reliable': 5947,\n",
       " 'traveled': 8933,\n",
       " 'conspiracy': 3511,\n",
       " 'strongest': 5568,\n",
       " 'lam': 9907,\n",
       " 'sidney': 2696,\n",
       " 'islands': 8294,\n",
       " 'elvira': 3058,\n",
       " 'status': 2665,\n",
       " 'penned': 7619,\n",
       " 'thankfully': 2670,\n",
       " 'handles': 5891,\n",
       " 'sandy': 8073,\n",
       " 'haunting': 2212,\n",
       " 'shocks': 7565,\n",
       " 'ae': 6668,\n",
       " 'cliches': 6201,\n",
       " 'bronte': 7775,\n",
       " 'christian': 1459,\n",
       " 'filmmakers': 1026,\n",
       " 'ealing': 7734,\n",
       " 'spent': 1066,\n",
       " 'clip': 4920,\n",
       " 'dime': 9245,\n",
       " 'expertise': 9649,\n",
       " 'enthralling': 8313,\n",
       " 'chaos': 4088,\n",
       " 'excuse': 1318,\n",
       " 'strikingly': 9433,\n",
       " 'green': 1372,\n",
       " 'sessions': 9186,\n",
       " 'poster': 3675,\n",
       " 'overweight': 9803,\n",
       " 'colored': 6463,\n",
       " 'majority': 2140,\n",
       " 'cardboard': 3418,\n",
       " 'notice': 1475,\n",
       " 'little': 117,\n",
       " 'cutting': 2367,\n",
       " 'hayes': 7125,\n",
       " 'gods': 5960,\n",
       " 'dolls': 4394,\n",
       " 'expand': 8985,\n",
       " 'glued': 6288,\n",
       " 'write': 883,\n",
       " 'fetish': 7644,\n",
       " 'mentions': 4894,\n",
       " 'snappy': 9323,\n",
       " 'uma': 5758,\n",
       " 'seriousness': 8304,\n",
       " 'clark': 2420,\n",
       " 'timeless': 3651,\n",
       " 'sebastian': 7253,\n",
       " 'confused': 1446,\n",
       " 'heels': 5940,\n",
       " 'nine': 2939,\n",
       " 'recent': 1114,\n",
       " 'renowned': 9559,\n",
       " 'justify': 4350,\n",
       " 'espionage': 7736,\n",
       " 'embarrassed': 2911,\n",
       " 'brazilian': 7960,\n",
       " 'mister': 7870,\n",
       " 'treated': 1888,\n",
       " 'happens': 560,\n",
       " 'shocker': 8261,\n",
       " 'spider': 4758,\n",
       " 'olympic': 9804,\n",
       " 'cher': 5711,\n",
       " 'pair': 2118,\n",
       " 'four': 674,\n",
       " 'willing': 1666,\n",
       " 'whimsical': 7773,\n",
       " 'daring': 3837,\n",
       " 'roots': 4982,\n",
       " 'chong': 6763,\n",
       " 'twilight': 4687,\n",
       " 'cabin': 2754,\n",
       " 'elvis': 3028,\n",
       " 'grinch': 4147,\n",
       " 'woods': 1378,\n",
       " 'girlfriend': 929,\n",
       " 'shocking': 1583,\n",
       " 'mixture': 4161,\n",
       " 'eight': 2290,\n",
       " 'butch': 6338,\n",
       " 'apprentice': 9152,\n",
       " 'noted': 3194,\n",
       " 'transformed': 5748,\n",
       " 'weakness': 5255,\n",
       " 'seventh': 8855,\n",
       " 'mack': 8003,\n",
       " 'flicks': 1521,\n",
       " 'kidnaps': 8472,\n",
       " 'rent': 832,\n",
       " 'spike': 3381,\n",
       " 'barry': 3358,\n",
       " 'hunt': 2270,\n",
       " 'cars': 1859,\n",
       " 'naschy': 5566,\n",
       " 'relief': 2114,\n",
       " 'touched': 2813,\n",
       " 'participants': 7174,\n",
       " 'icy': 8627,\n",
       " 'exchange': 5062,\n",
       " 'popular': 1044,\n",
       " 'daylight': 7004,\n",
       " 'ham': 4895,\n",
       " 'enchanted': 7100,\n",
       " 'neat': 3113,\n",
       " 'willie': 4848,\n",
       " 'bomb': 2145,\n",
       " 'health': 3317,\n",
       " 'remarks': 4607,\n",
       " 'remark': 7645,\n",
       " 'nancy': 2237,\n",
       " 'notices': 7967,\n",
       " 'paulie': 3692,\n",
       " 'byrne': 9399,\n",
       " 'caring': 2870,\n",
       " 'event': 1460,\n",
       " 'flowing': 7974,\n",
       " 'illustrated': 8718,\n",
       " 'coup': 5720,\n",
       " 'kathy': 6713,\n",
       " 'shannon': 7805,\n",
       " 'spectacularly': 9406,\n",
       " 'far': 228,\n",
       " 'trip': 1148,\n",
       " 'climbing': 7473,\n",
       " 'endure': 4300,\n",
       " 'develop': 2042,\n",
       " 'sh': 7878,\n",
       " 'nicely': 1764,\n",
       " 'visiting': 5256,\n",
       " 'crown': 6483,\n",
       " 'slasher': 1154,\n",
       " 'guns': 1843,\n",
       " 'busy': 2948,\n",
       " 'manipulated': 8086,\n",
       " 'implies': 7692,\n",
       " 'levant': 9123,\n",
       " 'option': 5372,\n",
       " 'bound': 2703,\n",
       " 'friendly': 2522,\n",
       " 'heartless': 8910,\n",
       " 'literature': 4577,\n",
       " 'challenging': 4702,\n",
       " 'ballroom': 8653,\n",
       " 'fairly': 997,\n",
       " 'resume': 7189,\n",
       " 'bursts': 9153,\n",
       " 'mother': 418,\n",
       " 'player': 1752,\n",
       " 'buddies': 3965,\n",
       " 'mad': 1136,\n",
       " 'ceremony': 8438,\n",
       " 'prevent': 3596,\n",
       " 'integrated': 9618,\n",
       " 'tortured': 3774,\n",
       " 'lands': 5224,\n",
       " 'excellently': 6160,\n",
       " 'serum': 6691,\n",
       " 'learns': 2240,\n",
       " 'convincingly': 4510,\n",
       " 'sports': 2228,\n",
       " 'crush': 4213,\n",
       " 'taxi': 4596,\n",
       " 'waits': 9225,\n",
       " 'swimming': 4373,\n",
       " 'communism': 8454,\n",
       " 'misfits': 9723,\n",
       " 'controversial': 3066,\n",
       " 'floors': 9594,\n",
       " 'addicted': 5186,\n",
       " 'pursued': 6894,\n",
       " 'remarkable': 1710,\n",
       " 'customers': 7526,\n",
       " 'hollow': 3869,\n",
       " 'additionally': 6919,\n",
       " 'coburn': 7258,\n",
       " 'technicolor': 5059,\n",
       " 'narration': 2533,\n",
       " 'mentality': 5639,\n",
       " 'badly': 892,\n",
       " 'produced': 1037,\n",
       " 'branch': 9070,\n",
       " 'du': 7222,\n",
       " 'three': 288,\n",
       " 'hotel': 1389,\n",
       " 'anguish': 8337,\n",
       " 'mouth': 1612,\n",
       " 'shop': 1962,\n",
       " 'pitt': 2521,\n",
       " 'banana': 9802,\n",
       " 'middle': 642,\n",
       " 'denied': 9263,\n",
       " 'capshaw': 9754,\n",
       " 'shaky': 5086,\n",
       " 'numbers': 1373,\n",
       " 'cracks': 7794,\n",
       " 'frankly': 2017,\n",
       " 'lap': 9486,\n",
       " 'boredom': 3241,\n",
       " 'relationships': 1501,\n",
       " 'draw': 2483,\n",
       " 'johnny': 1696,\n",
       " 'physically': 3082,\n",
       " 'entertained': 2156,\n",
       " 'district': 7577,\n",
       " 'hardy': 2713,\n",
       " 'angels': 2934,\n",
       " 'shouldn': 1588,\n",
       " 'initially': 2714,\n",
       " 'iq': 7281,\n",
       " 'request': 9326,\n",
       " 'eddie': 1704,\n",
       " 'spelling': 8298,\n",
       " 'kidnap': 6983,\n",
       " 'alex': 2204,\n",
       " 'air': 923,\n",
       " 'doesn': 152,\n",
       " 'relate': 2171,\n",
       " 'drift': 7789,\n",
       " 'keyboard': 9532,\n",
       " 'prostitute': 3948,\n",
       " 'punk': 4049,\n",
       " 'manners': 7015,\n",
       " 'mysteriously': 6825,\n",
       " 'spliced': 9867,\n",
       " 'boxer': 5327,\n",
       " 'admiration': 8028,\n",
       " 'sound': 474,\n",
       " 'experience': 574,\n",
       " 'record': 1838,\n",
       " 'imho': 7814,\n",
       " 'charms': 5677,\n",
       " 'screwed': 5770,\n",
       " 'novel': 640,\n",
       " 'roberts': 3221,\n",
       " 'works': 486,\n",
       " 'seymour': 6489,\n",
       " 'vaughn': 8050,\n",
       " 'escape': 1064,\n",
       " 'depicts': 4635,\n",
       " 'capital': 4654,\n",
       " 'shattering': 8988,\n",
       " 'flock': 6800,\n",
       " 'cos': 9701,\n",
       " 'cookie': 5721,\n",
       " 'needing': 7546,\n",
       " 'detail': 1569,\n",
       " 'though': 151,\n",
       " 'inexperienced': 8392,\n",
       " 'lionel': 6709,\n",
       " 'nolte': 5604,\n",
       " 'collector': 7199,\n",
       " 'kathryn': 5691,\n",
       " 'controversy': 7065,\n",
       " 'panahi': 8056,\n",
       " 'passion': 1776,\n",
       " 'limited': 1737,\n",
       " 'indifference': 9507,\n",
       " 'product': 2187,\n",
       " 'shanghai': 5028,\n",
       " 'johansson': 7121,\n",
       " 'sacred': 9596,\n",
       " 'bucks': 3576,\n",
       " 'continent': 8552,\n",
       " 'cushing': 5582,\n",
       " 'confuse': 7983,\n",
       " 'masterson': 6079,\n",
       " 'to': 6,\n",
       " 'was': 15,\n",
       " 'fear': 1059,\n",
       " 'bout': 7873,\n",
       " 'roof': 5280,\n",
       " 'dump': 6411,\n",
       " 'furthermore': 4073,\n",
       " 'guards': 6000,\n",
       " 'these': 133,\n",
       " 'shirley': 4166,\n",
       " 'obvious': 568,\n",
       " 'ok': 597,\n",
       " 'lambs': 9937,\n",
       " 'smoking': 3371,\n",
       " 'together': 292,\n",
       " 'boyle': 5109,\n",
       " 'toby': 6395,\n",
       " 'mean': 378,\n",
       " 'context': 1990,\n",
       " 'guevara': 7567,\n",
       " 'failing': 3705,\n",
       " 'sheep': 7543,\n",
       " 'titled': 3681,\n",
       " 'chilling': 2832,\n",
       " 'attributes': 8706,\n",
       " 'adapting': 9508,\n",
       " 'che': 2340,\n",
       " 'wit': 2172,\n",
       " 'complains': 9808,\n",
       " 'attic': 8105,\n",
       " 'red': 737,\n",
       " 'duryea': 9012,\n",
       " 'ernest': 7796,\n",
       " 'grudge': 5515,\n",
       " 'aren': 697,\n",
       " 'ghastly': 7857,\n",
       " 'loaded': 4820,\n",
       " 'feeling': 538,\n",
       " 'lift': 5756,\n",
       " 'adult': 1112,\n",
       " 'east': 2815,\n",
       " 'leia': 9264,\n",
       " 'technical': 1728,\n",
       " 'tiger': 4721,\n",
       " 'academy': 1771,\n",
       " 'takashi': 7599,\n",
       " 'scandal': 8543,\n",
       " 'grin': 7745,\n",
       " 'home': 340,\n",
       " 'fulfilled': 9928,\n",
       " 'noticed': 1909,\n",
       " 'sums': 5295,\n",
       " 'atlantis': 3907,\n",
       " 'spencer': 6317,\n",
       " 'join': 2846,\n",
       " 'laughed': 1473,\n",
       " 'enjoying': 2918,\n",
       " 'features': 921,\n",
       " 'lois': 5468,\n",
       " 'worthy': 1495,\n",
       " 'small': 386,\n",
       " 'quantum': 6457,\n",
       " 'variations': 9534,\n",
       " 'page': 1412,\n",
       " 'close': 482,\n",
       " 'jail': 2795,\n",
       " 'believability': 8134,\n",
       " 'ultimatum': 6475,\n",
       " 'hurry': 8617,\n",
       " 'passes': 4066,\n",
       " 'traditions': 7664,\n",
       " 'lightly': 8966,\n",
       " 'earth': 664,\n",
       " 'fable': 8871,\n",
       " 'widower': 8336,\n",
       " 'mexican': 2652,\n",
       " 'daytime': 7503,\n",
       " 'craven': 3731,\n",
       " 'becomes': 456,\n",
       " 'qualities': 2394,\n",
       " 'island': 1068,\n",
       " 'overtly': 8821,\n",
       " 'cinematographer': 4220,\n",
       " 'sexy': 1251,\n",
       " 'batman': 1291,\n",
       " 'crass': 9001,\n",
       " 'angry': 1601,\n",
       " 'rate': 945,\n",
       " 'pretty': 184,\n",
       " 'mountains': 3931,\n",
       " 'callahan': 9013,\n",
       " 'stricken': 8385,\n",
       " 'thereby': 7547,\n",
       " 'longest': 6225,\n",
       " 'stones': 6526,\n",
       " 'comic': 681,\n",
       " 'shelley': 4456,\n",
       " 'nostalgic': 4385,\n",
       " 'true': 281,\n",
       " 'conveys': 5512,\n",
       " 'unimpressive': 9510,\n",
       " 'villa': 8426,\n",
       " 'vargas': 7487,\n",
       " 'fierce': 8463,\n",
       " 'coherent': 3951,\n",
       " 'evil': 440,\n",
       " 'picking': 3606,\n",
       " 'wagner': 5237,\n",
       " 'false': 2515,\n",
       " 'winter': 3291,\n",
       " 'approach': 1467,\n",
       " 'graces': 9991,\n",
       " 'serious': 612,\n",
       " 'revelations': 9291,\n",
       " 'surprising': 1743,\n",
       " 'spell': 3318,\n",
       " 'confession': 8464,\n",
       " 'ultra': 3248,\n",
       " 'retelling': 9071,\n",
       " 'illogical': 4280,\n",
       " 'monologue': 6727,\n",
       " 'useless': 3476,\n",
       " 'unexpected': 2059,\n",
       " 'colonel': 4050,\n",
       " 'cinderella': 2185,\n",
       " 'mill': 4112,\n",
       " 'robin': 2076,\n",
       " 'meyers': 8934,\n",
       " 'debra': 6895,\n",
       " 'scares': 2569,\n",
       " 'naturally': 1943,\n",
       " 'expressed': 4938,\n",
       " 'quality': 481,\n",
       " 'correct': 2266,\n",
       " 'rose': 2103,\n",
       " 'myrna': 7647,\n",
       " 'thru': 4374,\n",
       " 'gibson': 6710,\n",
       " 'visions': 5532,\n",
       " 'rodney': 8091,\n",
       " 'be': 30,\n",
       " 'know': 123,\n",
       " 'impression': 1365,\n",
       " 'unusual': 1703,\n",
       " 'brush': 8135,\n",
       " 'fortunate': 7397,\n",
       " 'attempt': 579,\n",
       " 'emerge': 6045,\n",
       " 'attempting': 2913,\n",
       " 'traits': 6658,\n",
       " 'asks': 1626,\n",
       " 'weaknesses': 5522,\n",
       " 'ned': 2663,\n",
       " 'translated': 5395,\n",
       " 'miss': 699,\n",
       " 'granted': 2455,\n",
       " 'zombies': 1100,\n",
       " 'hearing': 2200,\n",
       " 'light': 624,\n",
       " 'parody': 2085,\n",
       " 'munchies': 9381,\n",
       " 'decidedly': 6380,\n",
       " 'nd': 3169,\n",
       " 'colour': 3298,\n",
       " 'ashraf': 9737,\n",
       " 'period': 792,\n",
       " 'ostensibly': 8074,\n",
       " 'fade': 5402,\n",
       " 'constructed': 4445,\n",
       " 'closeups': 9750,\n",
       " 'change': 638,\n",
       " 'troubled': 3166,\n",
       " 'anybody': 1706,\n",
       " 'technological': 9414,\n",
       " 'traitor': 9929,\n",
       " 'universally': 9661,\n",
       " 'claude': 5750,\n",
       " 'going': 170,\n",
       " 'sales': 7761,\n",
       " 'contrast': 2259,\n",
       " 'judd': 5997,\n",
       " 'repeating': 5629,\n",
       " 'recalls': 9614,\n",
       " 'hire': 3456,\n",
       " 'misfire': 9526,\n",
       " 'separation': 9962,\n",
       " 'hideous': 4173,\n",
       " 'young': 185,\n",
       " 'claiming': 5678,\n",
       " 'staying': 3970,\n",
       " 'bart': 8119,\n",
       " 'demonic': 5944,\n",
       " 'value': 1086,\n",
       " 'ease': 3941,\n",
       " 'moment': 547,\n",
       " 'hapless': 5670,\n",
       " 'joined': 4620,\n",
       " 'nightclub': 6396,\n",
       " 'appreciate': 1124,\n",
       " 'office': 1022,\n",
       " 'teens': 2476,\n",
       " 'stroke': 6561,\n",
       " 'head': 412,\n",
       " 'freed': 8223,\n",
       " 'helping': 2733,\n",
       " 'visconti': 7066,\n",
       " 'commit': 3484,\n",
       " 'weekend': 2389,\n",
       " 'tough': 1181,\n",
       " 'beware': 5576,\n",
       " 'bacall': 4636,\n",
       " 'encourages': 8946,\n",
       " 'eugene': 4932,\n",
       " 'acceptable': 3432,\n",
       " 'mourning': 9346,\n",
       " 'nice': 325,\n",
       " 'laura': 2867,\n",
       " 'virtues': 9430,\n",
       " 'explained': 1829,\n",
       " 'wasting': 3093,\n",
       " 'significantly': 8533,\n",
       " 'spy': 2411,\n",
       " 'le': 3400,\n",
       " 'despite': 460,\n",
       " 'admire': 3577,\n",
       " 'ppv': 9624,\n",
       " 'razor': 5882,\n",
       " 'contributed': 6740,\n",
       " 'psychological': 1953,\n",
       " 'socialist': 9879,\n",
       " 'reminiscent': 2755,\n",
       " 'excruciating': 6904,\n",
       " 'questions': 1183,\n",
       " 'busey': 6495,\n",
       " 'vocal': 5827,\n",
       " 'appropriate': 2282,\n",
       " 'pizza': 7659,\n",
       " 'traps': 7202,\n",
       " 'suspended': 9199,\n",
       " 'documentaries': 3652,\n",
       " 'bud': 4922,\n",
       " 'afternoon': 2606,\n",
       " 'aiello': 9266,\n",
       " 'smile': 1810,\n",
       " 'choir': 7381,\n",
       " 'progressed': 7512,\n",
       " 'watson': 4826,\n",
       " 'aspects': 1387,\n",
       " 'categories': 8108,\n",
       " 'tribe': 4897,\n",
       " '.': 2,\n",
       " 'local': 702,\n",
       " 'believing': 3310,\n",
       " 'sacrificed': 9431,\n",
       " 'sematary': 8882,\n",
       " 'romances': 6888,\n",
       " 'concert': 3212,\n",
       " 'briefly': 3333,\n",
       " 'whats': 4560,\n",
       " 'category': 2357,\n",
       " 'belushi': 4752,\n",
       " 'salvation': 6257,\n",
       " 'stardom': 6202,\n",
       " 'version': 311,\n",
       " 'realise': 3513,\n",
       " 'stranger': 3026,\n",
       " 'rupert': 7200,\n",
       " 'discover': 1952,\n",
       " 'frames': 5834,\n",
       " 'admirably': 9432,\n",
       " 'transcends': 9846,\n",
       " 'terminator': 6078,\n",
       " 'jodie': 6297,\n",
       " 'composer': 4987,\n",
       " 'scooby': 3334,\n",
       " 'examined': 8863,\n",
       " 'means': 801,\n",
       " 'haha': 9369,\n",
       " 'finish': 1339,\n",
       " 'crowd': 2247,\n",
       " 'ariel': 5662,\n",
       " 'bollywood': 2819,\n",
       " 'amitabh': 4435,\n",
       " 'derek': 3086,\n",
       " 'music': 225,\n",
       " 'june': 4621,\n",
       " 'maker': 2856,\n",
       " 'betrays': 9382,\n",
       " 'unbelievably': 3779,\n",
       " 'quarter': 6420,\n",
       " 'strings': 5771,\n",
       " 'bank': 1956,\n",
       " 'monty': 6064,\n",
       " 'carries': 2902,\n",
       " 'personally': 1249,\n",
       " 'macarthur': 4337,\n",
       " 'row': 3390,\n",
       " 'someone': 280,\n",
       " 'amateurs': 9910,\n",
       " 'distinction': 7947,\n",
       " 'tomb': 7020,\n",
       " 'tomei': 6928,\n",
       " 'foil': 7104,\n",
       " 'esther': 5296,\n",
       " 'dietrich': 8953,\n",
       " 'bombs': 5835,\n",
       " 'bsg': 6039,\n",
       " 'asian': 2148,\n",
       " 'forgetting': 6981,\n",
       " 'shouts': 9535,\n",
       " 'section': 2390,\n",
       " 'federal': 8635,\n",
       " 'unborn': 9516,\n",
       " 'pause': 6484,\n",
       " 'educational': 4933,\n",
       " 'bullying': 9806,\n",
       " 'stir': 9126,\n",
       " 'accuracy': 5022,\n",
       " 'establishment': 6539,\n",
       " 'lucille': 6861,\n",
       " 'deepest': 7919,\n",
       " 'argento': 9345,\n",
       " 'betty': 4688,\n",
       " 'accurate': 1839,\n",
       " 'returns': 1716,\n",
       " 'presumably': 3501,\n",
       " 'noteworthy': 6926,\n",
       " 'uncomfortable': 3109,\n",
       " 'sublime': 6414,\n",
       " 'tracking': 5362,\n",
       " 'spoke': 4597,\n",
       " 'dollars': 2463,\n",
       " 'exception': 1376,\n",
       " 'clan': 5624,\n",
       " 'territory': 3604,\n",
       " 'opportunity': 1401,\n",
       " 'slater': 7211,\n",
       " 'aware': 1869,\n",
       " 'dollar': 2824,\n",
       " 'amount': 1142,\n",
       " 'provided': 2387,\n",
       " 'lately': 4402,\n",
       " 'values': 1206,\n",
       " 'comfortable': 3946,\n",
       " 'compared': 1061,\n",
       " 'circumstances': 2304,\n",
       " 'bring': 705,\n",
       " 'slide': 6241,\n",
       " 'fodder': 7916,\n",
       " 'wannabe': 3751,\n",
       " 'darkly': 8052,\n",
       " 'pickup': 8162,\n",
       " 'knights': 8113,\n",
       " 'references': 2045,\n",
       " 'carla': 4835,\n",
       " 'casual': 5628,\n",
       " 'trials': 5861,\n",
       " 'experiencing': 6502,\n",
       " 'housewife': 5529,\n",
       " 'underdeveloped': 7820,\n",
       " 'realistically': 7105,\n",
       " 'occasional': 2516,\n",
       " 'deals': 2005,\n",
       " 'cult': 1175,\n",
       " 'giggle': 9072,\n",
       " 'nasty': 1575,\n",
       " 'advanced': 4629,\n",
       " 'roller': 5337,\n",
       " 'menace': 4255,\n",
       " 'stoltz': 9282,\n",
       " 'kill': 502,\n",
       " 'ah': 3687,\n",
       " 'trying': 265,\n",
       " 'billion': 8679,\n",
       " 'grumpy': 9408,\n",
       " 'miscast': 3197,\n",
       " 'unimaginative': 6240,\n",
       " 'glorious': 4146,\n",
       " 'izzard': 8778,\n",
       " 'engage': 4534,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to vector function\n",
    "\n",
    "Now we can write a function that converts a some text to a word vector. The function will take a string of words as input and return a vector with the words counted up. Here's the general algorithm to do this:\n",
    "\n",
    "* Initialize the word vector with [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html), it should be the length of the vocabulary.\n",
    "* Split the input string of text into a list of words with `.split(' ')`. Again, if you call `.split()` instead, you'll get slightly different results than what we show here.\n",
    "* For each word in that list, increment the element in the index associated with that word, which you get from `word2idx`.\n",
    "\n",
    "**Note:** Since all words aren't in the `vocab` dictionary, you'll get a key error if you run into one of those words. You can use the `.get` method of the `word2idx` dictionary to specify a default returned value when you make a key error. For example, `word2idx.get(word, None)` returns `None` if `word` doesn't exist in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    word_vec = np.zeros(len(vocab))\n",
    "    for word in text.split(\" \"):\n",
    "        if word in word2idx.keys():\n",
    "            word_vec[word2idx[word]] += 1\n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do this right, the following code should return\n",
    "\n",
    "```\n",
    "text_to_vector('The tea is for a party to celebrate '\n",
    "               'the movie so she has no time for a cake')[:65]\n",
    "                   \n",
    "array([0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
    "```       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  2.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  2.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector('The tea is for a party to celebrate '\n",
    "               'the movie so she has no time for a cake')[:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run through our entire review data set and convert each review to a word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(reviews), len(vocab)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(reviews.iterrows()):\n",
    "    word_vectors[ii] = text_to_vector(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18,   9,  27,   1,   4,   4,   6,   4,   0,   2,   2,   5,   0,\n",
       "          4,   1,   0,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  5,   4,   8,   1,   7,   3,   1,   2,   0,   4,   0,   0,   0,\n",
       "          1,   2,   0,   0,   1,   3,   0,   0,   0,   1],\n",
       "       [ 78,  24,  12,   4,  17,   5,  20,   2,   8,   8,   2,   1,   1,\n",
       "          2,   8,   0,   5,   5,   4,   0,   2,   1,   4],\n",
       "       [167,  53,  23,   0,  22,  23,  13,  14,   8,  10,   8,  12,   9,\n",
       "          4,  11,   2,  11,   5,  11,   0,   5,   3,   0],\n",
       "       [ 19,  10,  11,   4,   6,   2,   2,   5,   0,   1,   2,   3,   1,\n",
       "          0,   0,   0,   3,   1,   0,   1,   0,   0,   0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the first 5 word vectors\n",
    "word_vectors[:5, :23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test sets\n",
    "\n",
    "Now that we have the word_vectors, we're ready to split our data into train, validation, and test sets. Remember that we train on the train data, use the validation data to set the hyperparameters, and at the very end measure the network performance on the test data. Here we're using the function `to_categorical` from TFLearn to reshape the target data so that we'll have two output units and can classify with a softmax activation function. We actually won't be creating the validation set here, TFLearn will do that for us later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = (labels=='positive').astype(np.int_)\n",
    "records = len(labels)\n",
    "\n",
    "shuffle = np.arange(records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.9\n",
    "\n",
    "train_split, test_split = shuffle[:int(records*test_fraction)], shuffle[int(records*test_fraction):]\n",
    "trainX, trainY = word_vectors[train_split,:], to_categorical(Y.values[train_split], 2)\n",
    "testX, testY = word_vectors[test_split,:], to_categorical(Y.values[test_split], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "[TFLearn](http://tflearn.org/) lets you build the network by [defining the layers](http://tflearn.org/layers/core/). \n",
    "\n",
    "### Input layer\n",
    "\n",
    "For the input layer, you just need to tell it how many units you have. For example, \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 100])\n",
    "```\n",
    "\n",
    "would create a network with 100 input units. The first element in the list, `None` in this case, sets the batch size. Setting it to `None` here leaves it at the default batch size.\n",
    "\n",
    "The number of inputs to your network needs to match the size of your data. For this example, we're using 10000 element long vectors to encode our input data, so we need 10000 input units.\n",
    "\n",
    "\n",
    "### Adding layers\n",
    "\n",
    "To add new hidden layers, you use \n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, n_units, activation='ReLU')\n",
    "```\n",
    "\n",
    "This adds a fully connected layer where every unit in the previous layer is connected to every unit in this layer. The first argument `net` is the network you created in the `tflearn.input_data` call. It's telling the network to use the output of the previous layer as the input to this layer. You can set the number of units in the layer with `n_units`, and set the activation function with the `activation` keyword. You can keep adding layers to your network by repeated calling `net = tflearn.fully_connected(net, n_units)`.\n",
    "\n",
    "### Output layer\n",
    "\n",
    "The last layer you add is used as the output layer. There for, you need to set the number of units to match the target data. In this case we are predicting two classes, positive or negative sentiment. You also need to set the activation function so it's appropriate for your model. Again, we're trying to predict if some input data belongs to one of two classes, so we should use softmax.\n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "```\n",
    "\n",
    "### Training\n",
    "To set how you train the network, use \n",
    "\n",
    "```\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "Again, this is passing in the network you've been building. The keywords: \n",
    "\n",
    "* `optimizer` sets the training method, here stochastic gradient descent\n",
    "* `learning_rate` is the learning rate\n",
    "* `loss` determines how the network error is calculated. In this example, with the categorical cross-entropy.\n",
    "\n",
    "Finally you put all this together to create the model with `tflearn.DNN(net)`. So it ends up looking something like \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 10])                          # Input\n",
    "net = tflearn.fully_connected(net, 5, activation='ReLU')      # Hidden\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(net)\n",
    "```\n",
    "\n",
    "> **Exercise:** Below in the `build_model()` function, you'll put together the network using TFLearn. You get to choose how many layers to use, how many hidden units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    #### Your code ####\n",
    "    net = tflearn.input_data([None, 10000])                       # Input\n",
    "    net = tflearn.fully_connected(net, 10, activation='ReLU')   # Hidden\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.01, loss='categorical_crossentropy')\n",
    "    model = tflearn.DNN(net)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intializing the model\n",
    "\n",
    "Next we need to call the `build_model()` function to actually build the model. In my solution I haven't included any arguments to the function, but you can add arguments so you can change parameters in the model if you want.\n",
    "\n",
    "> **Note:** You might get a bunch of warnings here. TFLearn uses a lot of deprecated code in TensorFlow. Hopefully it gets updated to the new TensorFlow version soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Now that we've constructed the network, saved as the variable `model`, we can fit it to the data. Here we use the `model.fit` method. You pass in the training features `trainX` and the training targets `trainY`. Below I set `validation_set=0.1` which reserves 10% of the data set as the validation set. You can also set the batch size and number of epochs with the `batch_size` and `n_epoch` keywords, respectively. Below is the code to fit our the network to our word vectors.\n",
    "\n",
    "You can rerun `model.fit` to train the network further if you think you can increase the validation accuracy. Remember, all hyperparameter adjustments must be done using the validation set. **Only use the test set after you're completely done training the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3179  | total loss: \u001b[1m\u001b[32m0.50905\u001b[0m\u001b[0m | time: 4.093s\n",
      "| SGD | epoch: 020 | loss: 0.50905 - acc: 0.7653 -- iter: 20224/20250\n",
      "Training Step: 3180  | total loss: \u001b[1m\u001b[32m0.50738\u001b[0m\u001b[0m | time: 5.134s\n",
      "| SGD | epoch: 020 | loss: 0.50738 - acc: 0.7692 | val_loss: 0.48808 - val_acc: 0.7609 -- iter: 20250/20250\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=128, n_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "After you're satisified with your hyperparameters, you can run the network on the test set to measure it's performance. Remember, *only do this after finalizing the hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7784\n"
     ]
    }
   ],
   "source": [
    "predictions = (np.array(model.predict(testX))[:,0] >= 0.5).astype(np.int_)\n",
    "test_accuracy = np.mean(predictions == testY[:,0], axis=0)\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out your own text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function that uses your model to predict sentiment\n",
    "def test_sentence(sentence):\n",
    "    positive_prob = model.predict([text_to_vector(sentence.lower())])[0][1]\n",
    "    print('Sentence: {}'.format(sentence))\n",
    "    print('P(positive) = {:.3f} :'.format(positive_prob), \n",
    "          'Positive' if positive_prob > 0.5 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Moonlight is by far the best movie of 2016.\n",
      "P(positive) = 0.557 : Positive\n",
      "Sentence: It's amazing anyone could be talented enough to make something this spectacularly awful\n",
      "P(positive) = 0.411 : Negative\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Moonlight is by far the best movie of 2016.\"\n",
    "test_sentence(sentence)\n",
    "\n",
    "sentence = \"It's amazing anyone could be talented enough to make something this spectacularly awful\"\n",
    "test_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
